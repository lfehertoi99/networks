{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special\n",
    "from scipy.special import zeta, polygamma, factorial\n",
    "from networkx.algorithms import community\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onionlikeness_parameter(G):\n",
    "    \n",
    "    sum=0\n",
    "    k_max=max(d for (n,d) in G.degree())\n",
    "        \n",
    "    for k in range(k_max):\n",
    "        N_k=0\n",
    "        for node in G.nodes():\n",
    "            if G.degree(node)==k:\n",
    "                N_k+=1\n",
    "        #print(N_k)\n",
    "        \n",
    "        S_k=0\n",
    "        G_copy=G.copy()\n",
    "        for node in G.nodes():\n",
    "            if G.degree(node)>k:\n",
    "                G_copy.remove_node(node)\n",
    "        \n",
    "        for x in nx.connected_component_subgraphs(G_copy):\n",
    "            S=0\n",
    "            for node in x.nodes():\n",
    "                if x.degree(node)==k:\n",
    "                    S+=1\n",
    "            if S>S_k:\n",
    "                S_k=S\n",
    "        \n",
    "        if (N_k)!=0:\n",
    "            sum+=(S_k)/(N_k)\n",
    "        \n",
    "    onionlikeness = sum/(k_max)\n",
    "    return onionlikeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004242857142857143\n"
     ]
    }
   ],
   "source": [
    "simulations=20\n",
    "avg=0\n",
    "for x in range(simulations):\n",
    "    G=nx.erdos_renyi_graph(200,0.05)\n",
    "    avg+=onionlikeness_parameter(G)\n",
    "print(onionlikeness_parameter(G)/simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003413118131868132\n"
     ]
    }
   ],
   "source": [
    "simulations=20\n",
    "avg=0\n",
    "for x in range(simulations):\n",
    "    G=nx.barabasi_albert_graph(200,1)\n",
    "    avg+=onionlikeness_parameter(G)\n",
    "print(onionlikeness_parameter(G)/simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def optimize_partition():\n",
    " #   rho\n",
    "for i in range(3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_periphery_structure():\n",
    "    rho=sum(A_ij*del_ij)\n",
    "    A=nx.adjacency_matrix(G)\n",
    "    del_ij\n",
    "    #A is adjacency matrix of graph, del matrix is optimal c/p matrix. C/p structure is such that rho is maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_graph(G, updates, original_temperature,k,a):\n",
    "    onionlikeness=[]\n",
    "    modularity_list=[]\n",
    "    T = original_temperature\n",
    "    for x in range(updates):\n",
    "        list = np.random.choice(G.nodes(),2)\n",
    "        i = list[0]\n",
    "        j= list[1]\n",
    "        k_i = G.degree(i)\n",
    "        k_j = G.degree(j)\n",
    "        delta = np.absolute(k_i - k_j)\n",
    "        if i in range(core) and j in range(core):\n",
    "            if (i,j) in G.edges():\n",
    "                p=np.random.uniform()\n",
    "                if p<=a*(1/(1+delta)):\n",
    "                    G.remove_edge(i,j)\n",
    "                    onionlikeness.append(onionlikeness_parameter(G))\n",
    "                    print(\"OLP:\",onionlikeness_parameter(G))\n",
    "                    modularize(G)\n",
    "                    nw_modularity=modularity(G)\n",
    "                    modularity_list.append(nw_modularity)\n",
    "                    print(\"M:\",nw_modularity)\n",
    "        if i>=core and j>=core:\n",
    "            if (i,j) not in G.edges():\n",
    "                p=np.random.uniform()\n",
    "                if p<=a*delta:\n",
    "                    G.add_edge(i,j)\n",
    "                    onionlikeness.append(onionlikeness_parameter(G))\n",
    "                    print(\"OLP:\",onionlikeness_parameter(G))\n",
    "                    modularize(G)\n",
    "                    nw_modularity=modularity(G)\n",
    "                    modularity_list.append(nw_modularity)\n",
    "                    print(\"M:\",nw_modularity)\n",
    "        else:\n",
    "            if (i,j) in G.edges():\n",
    "                p=np.random.uniform()\n",
    "                if p<=T:\n",
    "                    G.remove_edge(i,j)\n",
    "                    onionlikeness.append(onionlikeness_parameter(G))\n",
    "                    print(\"OLP:\",onionlikeness_parameter(G))\n",
    "                    modularize(G)\n",
    "                    nw_modularity=modularity(G)\n",
    "                    modularity_list.append(nw_modularity)\n",
    "                    print(\"M:\",nw_modularity)\n",
    "            \n",
    "        T=T*k\n",
    "    plt.plot(modularity_list)\n",
    "    plt.plot(onionlikeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE PROBABILITY DISTRIBUTION FOR DEGREES OF SCALE-FREE NETWORK\n",
    "def degree_distribution(cutoff,gamma,xmin,N):\n",
    "    probabilities=np.zeros(cutoff+1)\n",
    "    normalization=scipy.special.zeta(gamma)\n",
    "\n",
    "    for i in range(cutoff):\n",
    "        probabilities[i]=(i+1)**(-gamma)\n",
    "        probabilities[i]/=normalization\n",
    "\n",
    "    psum=sum(probabilities)\n",
    "    remainder=1-sum(probabilities)\n",
    "\n",
    "    probabilities[cutoff]=remainder\n",
    "\n",
    "    degrees=np.linspace(1,cutoff+1,cutoff+1)\n",
    "    degree_distribution=np.random.choice(degrees,N,p=probabilities).astype(int)\n",
    "\n",
    "    #print(degree_distribution)\n",
    "    return degree_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE NETWORK WITH N NODES AND NO EDGES\n",
    "def onionnetwork(N):\n",
    "    G=nx.Graph()\n",
    "    for i in range(N):\n",
    "        G.add_node(i)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_layer_indices(G, degree_sequence):\n",
    "    attr=dict()\n",
    "    degrees=[]\n",
    "    for x in degree_sequence:\n",
    "        if x not in degrees:\n",
    "            degrees.append(x)\n",
    "    degrees.sort()\n",
    "    \n",
    "    for i in range(len(degrees)):\n",
    "        mindegree=degrees[i]\n",
    "        for node in G.nodes():\n",
    "            if degree_sequence[node]==mindegree:\n",
    "                nodeDict=dict()\n",
    "                nodeDict[\"layer\"]=i\n",
    "                attr[node]=nodeDict\n",
    "    nx.set_node_attributes(G,attr)\n",
    "    return(G)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JOIN \"STUBS\" OF NODE LINKS\n",
    "def join_stubs(G,distribution,error,a):\n",
    "    stubcount=np.copy(distribution)\n",
    "    for i in G.nodes():\n",
    "        for j in G.nodes():\n",
    "            if i!=j:\n",
    "                if stubcount[i]>0 and stubcount[j]>0:\n",
    "                    #calculate probability of joining: \n",
    "                    diff=np.absolute(G.nodes[i][\"layer\"]-G.nodes[j][\"layer\"])\n",
    "                    p=1/(a*(1+diff))\n",
    "                    x=np.random.uniform()                        \n",
    "                    #if random number smaller than p, join nodes, decrease stubcounts\n",
    "                    if x<=p:\n",
    "                        G.add_edge(i,j)\n",
    "                        stubcount[i]=stubcount[i]-1\n",
    "                        stubcount[j]=stubcount[j]-1\n",
    "    \n",
    "    while sum(stubcount)>error:\n",
    "        stubs=[]\n",
    "        edgelist=[]\n",
    "        for i in G.nodes():\n",
    "            if stubcount[i]>0:\n",
    "                stubs.append(i)\n",
    "        for x in G.edges():\n",
    "            edgelist.append(x)\n",
    "        swap=np.random.choice(stubs,2)\n",
    "        max=len(edgelist)\n",
    "        index=np.random.randint(0,max)\n",
    "        swapedge=edgelist[index]\n",
    "        node1=swap[0]\n",
    "        node2=swap[1]\n",
    "        node3=swapedge[0]\n",
    "        node4=swapedge[1]\n",
    "        G.remove_edge(node3,node4)\n",
    "        #print(\"removed:\",(node1,node2))\n",
    "        G.add_edge(node3,node1)\n",
    "        G.add_edge(node4,node2)\n",
    "        stubcount[node1]=stubcount[node1]-1\n",
    "        stubcount[node2]=stubcount[node2]-1\n",
    "        #print(sum(stubcount))\n",
    "                    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#girvan-newman algorithm for modularization\n",
    "def modularize(network):\n",
    "    communities_generator = community.girvan_newman(network)\n",
    "    #plt.figure(figsize=(5,5))\n",
    "    #nx.draw(network, node_size=15)\n",
    "    \n",
    "    comp = community.girvan_newman(network)\n",
    "    for communities in itertools.islice(comp, 5):\n",
    "        clusters=list(sorted(c) for c in communities)\n",
    "\n",
    "    modulenumber=len(list(clusters))\n",
    "    modulelist=list()\n",
    "    \n",
    "    for i in range(len(list(clusters))):\n",
    "        modulelist.append(clusters[i])\n",
    "    \n",
    "    attr=dict()\n",
    "    for i in range(modulenumber):\n",
    "        for node in modulelist[i]:\n",
    "            nodeDict=dict()\n",
    "            nodeDict[\"cluster\"]=i\n",
    "            attr[node]=nodeDict\n",
    "\n",
    "    nx.set_node_attributes(network,attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newman's definition of modularity is used\n",
    "def modularity(network):\n",
    "   \n",
    "    m=nx.number_of_edges(network) #number of edges in network\n",
    "    N=nx.number_of_nodes(network) #number of nodes in network\n",
    "    partialsum=0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if (i,j) in network.edges():\n",
    "                A=1\n",
    "            else:\n",
    "                A=0\n",
    "                \n",
    "            if network.nodes[i][\"cluster\"]==network.nodes[j][\"cluster\"]:\n",
    "                partialsum+=(A)-(((network.degree(i)*network.degree(j)))/(2*m))\n",
    "    \n",
    "    return partialsum/(2*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes=200\n",
    "core=20\n",
    "#create graphs\n",
    "G=nx.Graph()\n",
    "for x in range(nodes):\n",
    "    for y in range(nodes):\n",
    "        if x in range(core) or y in range(core):\n",
    "            G.add_edge(x,y)\n",
    "#nx.draw(G, node_size=20)\n",
    "onionlikeness_list=update_graph(G,500,20,0.8,1)\n",
    "#nx.draw(G_new, node_size=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(onionlikeness_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(modularity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot onionlikeness parameter and core/periphery coefficient at each step\n",
    "for a in [0.1,1,10,100]:\n",
    "    for e in [20,30,50,100]:\n",
    "        for c in [50,100,200,500]:\n",
    "            degrees=degree_distribution(c,2,2,200)\n",
    "            onion=onionnetwork(200)\n",
    "            node_layer_indices(onion,degrees)\n",
    "            join_stubs(onion, degrees, e, a)\n",
    "            print(\"generated onion network\",a , e, c, onionlikeness_parameter(onion))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
