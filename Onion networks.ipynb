{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONION NETWORK WITH SCALE-FREE DEGREE DISTRIBUTION\n",
    "\n",
    "#create probability distribution P(k)=a*k**(-gamma)\n",
    "#draw N numbers from this distribution: assign degree to each vertex (N vertices in network)\n",
    "#assign layer indices s_i according to degree (smallest degree=0, etc.)\n",
    "#join stubs with probability: p_ij = 1/(1+a*((s_i)-(s_j)))\n",
    "#reshuffling procedure for unused stubs: break up existing connections and make swaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.special\n",
    "from scipy.special import zeta, polygamma, factorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE PROBABILITY DISTRIBUTION FOR DEGREES OF SCALE-FREE NETWORK\n",
    "def degree_distribution(cutoff,gamma,xmin,N):\n",
    "    probabilities=np.zeros(cutoff+1)\n",
    "    normalization=scipy.special.zeta(gamma)\n",
    "\n",
    "    for i in range(cutoff):\n",
    "        probabilities[i]=(i+1)**(-gamma)\n",
    "        probabilities[i]/=normalization\n",
    "\n",
    "    psum=sum(probabilities)\n",
    "    remainder=1-sum(probabilities)\n",
    "\n",
    "    probabilities[cutoff]=remainder\n",
    "\n",
    "    degrees=np.linspace(1,cutoff+1,cutoff+1)\n",
    "    degree_distribution=np.random.choice(degrees,N,p=probabilities).astype(int)\n",
    "\n",
    "    #print(degree_distribution)\n",
    "    return degree_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE NETWORK WITH N NODES AND NO EDGES\n",
    "def onionnetwork(N):\n",
    "    G=nx.Graph()\n",
    "    for i in range(N):\n",
    "        G.add_node(i)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_layer_indices(G, degree_sequence):\n",
    "    attr=dict()\n",
    "    degrees=[]\n",
    "    for x in degree_sequence:\n",
    "        if x not in degrees:\n",
    "            degrees.append(x)\n",
    "    degrees.sort()\n",
    "    \n",
    "    for i in range(len(degrees)):\n",
    "        mindegree=degrees[i]\n",
    "        for node in G.nodes():\n",
    "            if degree_sequence[node]==mindegree:\n",
    "                nodeDict=dict()\n",
    "                nodeDict[\"layer\"]=i\n",
    "                attr[node]=nodeDict\n",
    "    nx.set_node_attributes(G,attr)\n",
    "    return(G)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_layer_indices_rand(G,distribution):\n",
    "    attr=dict()\n",
    "    degrees=[]\n",
    "    for x in distribution:\n",
    "        if x not in degrees:\n",
    "            degrees.append(x)\n",
    "    degrees.sort()\n",
    "    \n",
    "    for i in range(len(degrees)):\n",
    "        mindegree=degrees[i]\n",
    "        for node in G.nodes():\n",
    "            if G.degree(node)==mindegree:\n",
    "                nodeDict=dict()\n",
    "                nodeDict[\"layer\"]=i\n",
    "                attr[node]=nodeDict\n",
    "    nx.set_node_attributes(G,attr)\n",
    "    return(G)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JOIN \"STUBS\" OF NODE LINKS\n",
    "def join_stubs(G,distribution,error):\n",
    "    stubcount=np.copy(distribution)\n",
    "    for i in G.nodes():\n",
    "        for j in G.nodes():\n",
    "            if i!=j:\n",
    "                if stubcount[i]>0 and stubcount[j]>0:\n",
    "                    #calculate probability of joining: \n",
    "                    diff=np.absolute(G.nodes[i][\"layer\"]-G.nodes[j][\"layer\"])\n",
    "                    p=1/(1+diff)\n",
    "                    x=np.random.uniform()                        \n",
    "                    #if random number smaller than p, join nodes, decrease stubcounts\n",
    "                    if x<=p:\n",
    "                        G.add_edge(i,j)\n",
    "                        stubcount[i]=stubcount[i]-1\n",
    "                        stubcount[j]=stubcount[j]-1\n",
    "    \n",
    "    while sum(stubcount)>error:\n",
    "        stubs=[]\n",
    "        edgelist=[]\n",
    "        for i in G.nodes():\n",
    "            if stubcount[i]>0:\n",
    "                stubs.append(i)\n",
    "        for x in G.edges():\n",
    "            edgelist.append(x)\n",
    "        swap=np.random.choice(stubs,2)\n",
    "        max=len(edgelist)\n",
    "        index=np.random.randint(0,max)\n",
    "        swapedge=edgelist[index]\n",
    "        node1=swap[0]\n",
    "        node2=swap[1]\n",
    "        node3=swapedge[0]\n",
    "        node4=swapedge[1]\n",
    "        G.remove_edge(node3,node4)\n",
    "        #print(\"removed:\",(node1,node2))\n",
    "        G.add_edge(node3,node1)\n",
    "        G.add_edge(node4,node2)\n",
    "        stubcount[node1]=stubcount[node1]-1\n",
    "        stubcount[node2]=stubcount[node2]-1\n",
    "        #print(sum(stubcount))\n",
    "                    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robustness of network\n",
    "def get_robustness(network):\n",
    "    summa=0\n",
    "    networksize=network.number_of_nodes()\n",
    "    for i in range(Gc.number_of_nodes()):\n",
    "        graph=Gc.copy()\n",
    "        list=np.array(graph.nodes())\n",
    "        nodelist=np.random.choice(list,i, replace=False)\n",
    "        for j in nodelist:\n",
    "            graph.remove_node(j)\n",
    "        connected=max(nx.connected_component_subgraphs(graph), key=len)\n",
    "        size=len(connected)\n",
    "        summa+=size/networksize\n",
    "    #print(summa/size)\n",
    "    return(summa/networksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUNT NUMBER OF SHELLS IN NETWORK\n",
    "def countshells(G):\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    list=[0]\n",
    "    i=1\n",
    "    shells=0\n",
    "    while list!=[]:\n",
    "        list=[]\n",
    "        for node in nx.k_shell(G,i):\n",
    "            list.append(node)\n",
    "        shells+=1\n",
    "        i+=1\n",
    "    return shells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DICTIONARY OF NODES:K-INDICES, SET AS NODE ATTRIBUTES IN GRAPH\n",
    "def k_core_decomposition(G, shell_count):\n",
    "    attr=dict()\n",
    "    \n",
    "    for i in range(shell_count):\n",
    "        for node in nx.k_shell(G,i).nodes():\n",
    "            nodeDict=dict()\n",
    "            nodeDict[\"k-shell index\"]=i\n",
    "            attr[node]=nodeDict\n",
    "           \n",
    "    nx.set_node_attributes(G,attr)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_color_map(G):\n",
    "    color=[]\n",
    "    labels=dict()\n",
    "    for node in G.nodes():\n",
    "        color.append(G.nodes[node][\"k-shell index\"])\n",
    "        labels[node]=str(G.nodes[node][\"k-shell index\"])\n",
    "    netLayout=nx.spring_layout(G,weight='weight')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    nx.draw(G,netLayout,node_color=color,cmap=\"OrRd\",node_size=50)\n",
    "    #nx.draw_networkx_labels(G,netLayout,labels,font_size=16)#a második egy ilyen positionös cucc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET DICTIONARY OF NODES IN SHELLS\n",
    "def shells(G, shell_count):\n",
    "    shells=dict()\n",
    "    for i in range(shell_count):\n",
    "        list=[]\n",
    "        for node in nx.k_shell(G,i).nodes():\n",
    "            list.append(node)\n",
    "        shells[i]=list\n",
    "    return shells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_dict(G): #returns dictionary with layer indices as keys, and list of nodes as values\n",
    "    attributes=nx.get_node_attributes(G,\"layer\")\n",
    "    layerdict=dict()\n",
    "    for x in range(max(attributes.values())+1):\n",
    "        layerdict[x]=[]\n",
    "    for k,v in attributes.items():\n",
    "        layerdict[v].append(k)\n",
    "    \n",
    "    return(layerdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_layer(G): #index of highest layer in network = number of layers\n",
    "    highest_layer=max(nx.get_node_attributes(G,\"layer\").values())\n",
    "    return highest_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onion_similarity(G, layerdict,highestlayer):\n",
    "    totalerror=[]\n",
    "    for i in range(highestlayer): #highestlayer=number of layers\n",
    "        for j in range(highestlayer):\n",
    "            if i>=j: #only do each combination once :P\n",
    "                links=0\n",
    "                if layerdict[i]!=[] and layerdict[j]!=[]: #if there are nodes in the layer\n",
    "                    for p in layerdict[i]:\n",
    "                        for q in layerdict[j]:\n",
    "                            if p>=q and (p,q) in G.edges():\n",
    "                                links+=1 #check if p and q are linked. if yes, add 1 to number of links.\n",
    "                    #print(\"links between\",i,\"and\",j,\":\",links)\n",
    "                    pi=len(layerdict[i]) #number of nodes in layer i \n",
    "                    pj=len(layerdict[j]) #number of nodes in layer j\n",
    "                    possible=((pi)*(pj))/2 #number of links possible between the two layers\n",
    "                    real_prob=links/possible #probability of any two nodes, one in i, one in j, being linked.\n",
    "                    exp_prob=1/(1+np.absolute(i-j)) #probability of there being a link if the network were onion-type.\n",
    "                    error=np.absolute(exp_prob-real_prob) #difference between the actual and the \"onion-type\" probability\n",
    "                    totalerror.append(error) #add this difference to the list totalerror\n",
    "    errorsum=0\n",
    "    mean=sum(totalerror)/len(totalerror)\n",
    "    for x in totalerror: \n",
    "        squared_diff=(x-mean)**2\n",
    "        errorsum+=squared_diff\n",
    "    mean_squared_error=(errorsum/len(totalerror))**0.5\n",
    "    return mean_squared_error/(highestlayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomerror(x,degree_distribution):\n",
    "    \n",
    "    degrees=degree_distribution\n",
    "    if sum(degrees)%2==1:\n",
    "        degrees[0]+=1\n",
    "    G=nx.configuration_model(degrees)\n",
    "    node_layer_indices_rand(G,degrees)\n",
    "\n",
    "    layerdict=layer_dict(G)\n",
    "    highestlayer=highest_layer(G)\n",
    "    print(\"random highest layer\",highestlayer)\n",
    "    onionerror_random=onion_similarity(G,layerdict,highestlayer)\n",
    "    \n",
    "    return onionerror_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onionerror(x,degree_distribution):\n",
    "    \n",
    "    g=onionnetwork(x)\n",
    "    node_layer_indices(g,degree_distribution)\n",
    "\n",
    "    H=join_stubs(g,degrees,125)\n",
    "    H=max(nx.connected_component_subgraphs(H), key=len)\n",
    "    \n",
    "    layerdict=layer_dict(H)\n",
    "    highestlayer=highest_layer(H)\n",
    "    print(\"onion highest layer\",highestlayer)\n",
    "    onionerror_onion=onion_similarity(H,layerdict,highestlayer)\n",
    "    \n",
    "    return onionerror_onion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_links(G,a):\n",
    "    layers=layer_dict(G)\n",
    "    highestlayer=max(nx.get_node_attributes(G,\"layer\").values())\n",
    "    population=[0]*highestlayer\n",
    "    for x in range(highestlayer):\n",
    "        population[x]=len(layers[x])\n",
    "    sum=0\n",
    "    for i in range(highestlayer):\n",
    "        for j in range(highestlayer):\n",
    "            if i>j:\n",
    "                diff=np.absolute(i-j)\n",
    "                p=1/(1+(a*diff))\n",
    "                #print(p)\n",
    "                ni=len(layers[i])\n",
    "                nj=len(layers[j])\n",
    "                sum+=(ni*nj)*p\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 50\n",
      "p: 0.01\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-abb485ac04e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"p:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mdegrees\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdegree_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0merr_onion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0monionerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdegree_distribution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;31m#print(\"onion:\", err_onion)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0merr_rand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandomerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdegree_distribution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-b7cc0b6dcd00>\u001b[0m in \u001b[0;36monionerror\u001b[1;34m(x, degree_distribution)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0monionnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mnode_layer_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdegree_distribution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mH\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjoin_stubs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m125\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-457dd653cf98>\u001b[0m in \u001b[0;36mnode_layer_indices\u001b[1;34m(G, degree_sequence)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mattr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdegrees\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdegree_sequence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mdegrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "for N in [50,100,200,500]:\n",
    "    print(\"number of nodes:\",N)\n",
    "    for p in [0.01,0.05,0.1,0.15,0.2,0.5,0.7]:\n",
    "        print(\"p:\",p)\n",
    "        degrees=degree_distribution(100,2,2,N)\n",
    "        err_onion=onionerror(N,degree_distribution)\n",
    "        #print(\"onion:\", err_onion)\n",
    "        err_rand=randomerror(N,degree_distribution)\n",
    "        #print(\"random:\",err_rand)\n",
    "        print(err_onion/err_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degrees=degree_distribution(100,2,2,500)\n",
    "#network=onionnetwork(500)\n",
    "#node_layer_indices(network,degrees)\n",
    "#join_stubs(network, degrees,125)\n",
    "#nx.get_node_attributes(network,\"layer\")\n",
    "#plt.figure(figsize=(10,10))\n",
    "#Gc = max(nx.connected_component_subgraphs(network), key=len)\n",
    "#plt.figure(figsize=(8,8))\n",
    "#nx.draw(Gc, node_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulations=20\n",
    "#for x in range(simulations):\n",
    " #   degrees=degree_distribution(100,2,2,500)\n",
    "  #  network=onionnetwork(500)\n",
    "   # node_layer_indices(network,degrees)\n",
    "    #join_stubs(network,degrees,125)\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    #Gc = max(nx.connected_component_subgraphs(network), key=len)\n",
    "    #nx.draw(Gc, node_size=50)\n",
    "    #print(\"robustness:\",get_robustness(Gc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
